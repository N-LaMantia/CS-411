{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ba9b0c4-a99c-4db2-9f7a-de61f2ff2b61",
   "metadata": {},
   "source": [
    "This is a binary classification model built for Logistical Regression.\n",
    "We are testing age versus annual income to depict two groups of spenders (high and low), \n",
    "then using a Train-Test-Split to randomly select a percentage of the data to train our\n",
    "model with, and the rest of the data to test the model. After we have trained the model \n",
    "and tested it, we created evaluation statistics to score the trained model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "359ed383-80a5-47f2-83cc-b63188c1ef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "#this is for the training of the model \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc, classification_report, r2_score\n",
    "#to test accuracy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#this is for binary classification\n",
    "\n",
    "\n",
    "#reading data\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\nicke\\\\Downloads\\\\Mall_Customers.csv\").dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7409db-5ad4-45e0-bff1-2986e07560be",
   "metadata": {},
   "source": [
    "Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a840460f-b9e3-43d9-b5f0-8c7c0dee375a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train test split for the dataset\n",
    "x = data[\"Age\"]\n",
    "y = data[\"Annual Income (k$)\"]\n",
    "data[\"Spender Category\"] = pd.cut(\n",
    "    data[\"Spending Score (1-100)\"], \n",
    "    bins=[0, 50, 100], \n",
    "    labels=[\"Low\", \"High\"]\n",
    ")\n",
    "#for gender, it is two features. male 0 male 1, female 0, female 1\n",
    "if 'Gender' in data.columns:\n",
    "    data[\"Gender Male Num\"] = data[\"Gender\"] == \"Male\"\n",
    "    data[\"Gender Female Num\"] = data[\"Gender\"] == \"Female\"\n",
    "else:\n",
    "    print(\"Gender column not found!\")\n",
    "\n",
    "#split age into three features\n",
    "if 'Age' in data.columns:\n",
    "    data['Age 1-25'] = (data['Age'] >= 1) & (data['Age'] <= 25)\n",
    "    data['Age 26-50'] = (data['Age'] >= 26) & (data['Age'] <= 50)\n",
    "    data['Age 51-100'] = (data['Age'] >= 51) & (data['Age'] <= 100)\n",
    "else:\n",
    "    print(\"Age column not found!\")\n",
    "\n",
    "#drop the columns not in use\n",
    "data[\"Spender Category Num\"] = data[\"Spender Category\"].map({\"Low\": 0, \"High\": 1})\n",
    "\n",
    "#data[\"Gender Male Num\"] = data[\"Gender\"] == \"Male\"\n",
    "#data[\"Gender Female Num\"] = data[\"Gender\"] == \"Female\" #seperate to two columns \n",
    "#data = data.copy().drop(['CustomerID', 'Gender'], axis=1)\n",
    "data = data[data['Annual Income (k$)'] < 130]\n",
    "\n",
    "#train, test = train_test_split(data, train_size = 0.7)\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size = 0.2) #random_state = 100 is the seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf6e29d-6fba-44a1-a307-efe4d10d3891",
   "metadata": {},
   "source": [
    "Selecting Features (training and testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5dd5212e-04f1-4d52-bcd0-857c7cb5320e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:  [[-0.04936696  0.47101288  0.1317454  -0.6079525   0.11718956 -0.12238378]]\n",
      "Coefficients:  [[-0.20890901  0.55540132  0.09820327 -0.71468255  0.12416908 -0.18524703]]\n",
      "Coefficients:  [[-0.14570802  0.34649288  0.18659167 -0.59017568  0.11251294 -0.16960407]]\n",
      "Coefficients:  [[-0.19236843  0.56835046  0.16865154 -0.75731005  0.08589518 -0.10620323]]\n",
      "Coefficients:  [[-0.02314511  0.4488639   0.1837713  -0.65534435  0.06212484 -0.08483399]]\n",
      "Coefficients:  [[-5.71649704e-04  5.16447123e-01  1.26567736e-01 -6.96713291e-01\n",
      "  -4.90985738e-02 -4.59985951e-03]]\n",
      "Coefficients:  [[ 0.11183945  0.40629316  0.22739112 -0.75705268  0.05330065 -0.17666905]]\n",
      "Coefficients:  [[-0.06780785  0.46969986  0.16097952 -0.68175801 -0.00285195 -0.04822668]]\n",
      "Coefficients:  [[ 0.14948212  0.42106068  0.07187212 -0.60243388  0.04202726 -0.15152835]]\n",
      "Coefficients:  [[-0.27515478  0.47009815  0.19129868 -0.65733961  0.07226648 -0.06820925]]\n",
      "              Feature  Average Weight\n",
      "0  Annual Income (k$)       -0.070171\n",
      "1            Age 1-25        0.467372\n",
      "2           Age 26-50        0.154707\n",
      "3          Age 51-100       -0.672076\n",
      "4     Gender Male Num        0.061754\n",
      "5   Gender Female Num       -0.111751\n",
      "Scores for each fold: [0.3        0.3        0.5        0.7        0.5        0.7\n",
      " 0.5        0.5        0.6        0.6        0.6        0.5\n",
      " 0.3        0.5        0.6        0.5        0.6        0.6\n",
      " 0.55555556 0.33333333]\n",
      "Average accuracy: 0.5144444444444444\n"
     ]
    }
   ],
   "source": [
    "#select features (training)\n",
    "train_x = data[['Annual Income (k$)', 'Age']]\n",
    "\n",
    "train_y = data[['Spender Category Num']].values.ravel()\n",
    "\n",
    "#select features (testing)\n",
    "test_x = data[['Annual Income (k$)', 'Age 1-25', 'Age 26-50', 'Age 51-100', 'Gender Male Num', 'Gender Female Num']]\n",
    "test_y = data[['Spender Category Num']].values.ravel()\n",
    "#this is repeated below....\n",
    "\n",
    "\n",
    "#scale the data (numeric)\n",
    "columns = [\"Annual Income (k$)\"]\n",
    "data[columns] = (data[columns] - data[columns].min()) / (data[columns].max() - data[columns].min())\n",
    "\n",
    "#scale the data\n",
    "age_columns = [\"Age 1-25\", \"Age 26-50\", \"Age 51-100\"]\n",
    "data[age_columns] = data[age_columns].astype(float) #convert to 1 or 0\n",
    "\n",
    "#min-max scaling\n",
    "data[age_columns] = (data[age_columns] - data[age_columns].min()) / (data[age_columns].max() - data[age_columns].min())\n",
    "\n",
    "model = LogisticRegression(solver = 'liblinear')\n",
    "#model can also be a different type. \n",
    "\n",
    "model_1 = KFold(n_splits = 20, shuffle = True, random_state = None)\n",
    "#model_1.fit(train_x, train_y)\n",
    "\n",
    "scores = cross_val_score(model, test_x, test_y, cv=model_1, scoring='accuracy')\n",
    "\n",
    "#new\n",
    "X = data[['Annual Income (k$)', 'Age 1-25', 'Age 26-50', 'Age 51-100', \"Gender Male Num\", \"Gender Female Num\"]]\n",
    "y = data[['Spender Category Num']].values.ravel()\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "feature_weights = np.zeros((kf.get_n_splits(), X.shape[1]))  # Store weights for each fold\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    #.iloc\n",
    "    model = LogisticRegression(solver = 'liblinear')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    feature_weights[i, :] = model.coef_\n",
    "    print(\"Coefficients: \", model.coef_)\n",
    "\n",
    "# Compute average weights across folds\n",
    "average_weights = np.mean(feature_weights, axis=0)\n",
    "\n",
    "# Store in a DataFrame\n",
    "weights_df = pd.DataFrame({\"Feature\": X.columns, \"Average Weight\": average_weights})\n",
    "print(weights_df)\n",
    "\n",
    "#-----------------------\n",
    "\n",
    "\n",
    "# Print the scores for each fold\n",
    "print(\"Scores for each fold:\", scores)\n",
    "\n",
    "# Print the average accuracy\n",
    "print(\"Average accuracy:\", scores.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbd400a-104e-4f38-8c6c-2d9bdd040058",
   "metadata": {},
   "source": [
    "Evauluation of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ee94c7e6-f3f6-494e-a1a1-a788c918865c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KFold' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[103], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#evaluation of the model \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m predicted \u001b[38;5;241m=\u001b[39m model_1\u001b[38;5;241m.\u001b[39mpredict(test_x)\n\u001b[0;32m      3\u001b[0m cmatrix \u001b[38;5;241m=\u001b[39m confusion_matrix(test_y, predicted)\n\u001b[0;32m      4\u001b[0m TN, FP, FN, TP \u001b[38;5;241m=\u001b[39m cmatrix\u001b[38;5;241m.\u001b[39mravel()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KFold' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "#evaluation of the model \n",
    "predicted = model_1.predict(test_x)\n",
    "cmatrix = confusion_matrix(test_y, predicted)\n",
    "TN, FP, FN, TP = cmatrix.ravel()\n",
    "accuracy = (TP + TN)/(TP + TN + FP + FN)\n",
    "precision = (TP)/(TP + FP)\n",
    "recall = (TP)/(TP + FN)\n",
    "F1 = 2 * (precision * recall)/(precision + recall)\n",
    "r2 = 1\n",
    "print(\"accuracy: \", accuracy)\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1 Score: \", F1)\n",
    "print(\"R^2 Score: \", r2, \". This is used for Linear Regression.\")\n",
    "print(\"Confusion Matrix: \")\n",
    "\n",
    "print(cmatrix)\n",
    "\n",
    "\n",
    "#visualization\n",
    "# apply normalization techniques \n",
    "'''\n",
    "for column in data.columns: \n",
    "    data[column] = (data[column] - data[column].min()) / (data[column].max() - data[column].min())     \n",
    "  \n",
    "# view normalized data \n",
    "data.plot(kind = 'bar')\n",
    "print(data)\n",
    "'''\n",
    "#plt.bar(['High Spenders', 'Low Spenders'], data[HighSpenders, LowSpenders]) #fix this \n",
    "#plt.title('High Low')\n",
    "#plt.xlabel('Spenders')\n",
    "#plt.ylabel('Amount')\n",
    "#plt.show()\n",
    "\n",
    "#print(\"Low Spenders: \" + str(LowSpenders))\n",
    "#print(\"High Spenders: \" + str(HighSpenders))\n",
    "\n",
    "#Computing ROC Curve\n",
    "\n",
    "probabilities = model_1.predict_proba(test_x)[:, 1]  # Probabilities for high spending class\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(test_y, probabilities)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "#plot the curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(false_positive_rate, true_positive_rate, color=\"blue\", lw=2, label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], color=\"gray\", linestyle=\"--\")  # Diagonal Line\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#More code\n",
    "\n",
    "\n",
    "#print(\"Prediction: \" + lr.predict(data, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9a987c-4df0-42b9-bc25-2bba002f78c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
